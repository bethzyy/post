#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è§†é¢‘ç”Ÿæˆå¯¹æ¯”å·¥å…·
æ”¯æŒå¤šä¸ªè§†é¢‘ç”Ÿæˆæ¨¡å‹,å¯¹åŒä¸€ä¸»é¢˜ç”Ÿæˆè§†é¢‘å¹¶AIç‚¹è¯„æ’åº
"""

import sys
import os
from pathlib import Path
import json
import requests
from datetime import datetime
import subprocess
import tempfile

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from config import get_zhipuai_client


# è§†é¢‘ç”Ÿæˆæ¨¡å‹é…ç½®(ä»…åŒ…å«çœŸæ­£æ”¯æŒè§†é¢‘ç”Ÿæˆçš„æ¨¡å‹)
VIDEO_GENERATION_MODELS = {
    'dalle-animation': {
        'name': 'DALL-E 3 + FFmpegåŠ¨ç”»',
        'description': 'ä½¿ç”¨DALL-Eç”Ÿæˆå›¾ç‰‡,FFmpegåˆ›å»ºç¼©æ”¾åŠ¨ç”»æ•ˆæœ',
        'provider': 'OpenAI + FFmpeg',
        'type': 'img-to-video',
        'enabled': True  # å¯ç”¨,ç­‰å¾…APIé…é¢æ¢å¤
    },
    'seedance': {
        'name': 'Seedance 1.5 Pro (ç«å±±å¼•æ“)',
        'description': 'ç«å±±å¼•æ“è±†åŒ…æœ€æ–°è§†é¢‘ç”Ÿæˆæ¨¡å‹,æ”¯æŒæ–‡å­—è½¬è§†é¢‘+éŸ³é¢‘',
        'provider': 'Volcano Engine',
        'type': 'text-to-video',
        'enabled': True  # å·²å¼€é€š,ä½¿ç”¨VOLCANO_API_KEY
    },
    'gemini-veo': {
        'name': 'Gemini Veo 3.1 (Google)',
        'description': 'Googleæœ€æ–°è§†é¢‘ç”Ÿæˆæ¨¡å‹,æ”¯æŒ8ç§’é«˜æ¸…è§†é¢‘ç”Ÿæˆ',
        'provider': 'Google',
        'type': 'text-to-video',
        'enabled': False  # éœ€è¦Google Cloud API key
    }
}


def generate_with_pollinations(prompt, output_path):
    """ä½¿ç”¨Pollinations.aiç”Ÿæˆå›¾ç‰‡(æ³¨æ„:å®é™…è¿”å›å›¾ç‰‡è€Œéè§†é¢‘)"""

    try:
        print(f"[Pollinations Image] æ­£åœ¨ç”Ÿæˆå›¾ç‰‡...")
        print(f"  æç¤ºè¯: {prompt[:100]}...")

        # ç¼–ç æç¤ºè¯
        encoded_prompt = requests.utils.quote(prompt)

        # Pollinationså›¾ç‰‡API
        image_url = f"https://image.pollinations.ai/prompt/{encoded_prompt}?width=512&height=512&seed=123&nologo=true&enh=true"

        # è¯·æ±‚å›¾ç‰‡
        response = requests.get(image_url, timeout=120)

        if response.status_code == 200:
            # ä¿å­˜æ–‡ä»¶
            with open(output_path, 'wb') as f:
                f.write(response.content)

            file_size = len(response.content)

            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            file_type = "unknown"

            # æ£€æŸ¥JPEG
            if response.content[:2] == b'\xff\xd8':
                file_type = "jpeg"
            # æ£€æŸ¥PNG
            elif b'PNG' in response.content[:100]:
                file_type = "png"
            # æ£€æŸ¥GIF
            elif response.content[:6] in [b'GIF87a', b'GIF89a']:
                file_type = "gif"
            # æ£€æŸ¥MP4
            elif b'ftypmp42' in response.content[:100] or b'ftypisom' in response.content[:100]:
                file_type = "mp4"

            print(f"[æˆåŠŸ] æ–‡ä»¶å·²ä¿å­˜: {output_path}")
            print(f"  å¤§å°: {file_size} bytes")
            print(f"  ç±»å‹: {file_type}")

            return {
                'success': True,
                'file_path': str(output_path),
                'file_size': file_size,
                'file_type': file_type,
                'message': f"æˆåŠŸç”Ÿæˆ {file_type.upper()} æ–‡ä»¶"
            }
        else:
            return {
                'success': False,
                'error': f"HTTP {response.status_code}",
                'message': f"è¯·æ±‚å¤±è´¥: {response.status_code}"
            }

    except requests.exceptions.Timeout:
        return {
            'success': False,
            'error': 'timeout',
            'message': 'è¯·æ±‚è¶…æ—¶(120ç§’)'
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': f"ç”Ÿæˆå¤±è´¥: {str(e)[:100]}"
        }


def generate_video_with_dalle_first(prompt, output_path):
    """å…ˆç”ŸæˆDALL-Eå›¾ç‰‡,ç„¶åè½¬æ¢ä¸ºç®€å•åŠ¨ç”»"""

    try:
        print(f"[DALL-E + åŠ¨ç”»] æ­£åœ¨ç”Ÿæˆ...")

        # ç¬¬ä¸€æ­¥: ç”Ÿæˆå›¾ç‰‡
        from config import get_antigravity_client
        client = get_antigravity_client()

        if not client:
            return {
                'success': False,
                'error': 'no_client',
                'message': 'æ— æ³•è·å–anti-gravityå®¢æˆ·ç«¯'
            }

        print(f"  [1/2] ç”ŸæˆåŸºç¡€å›¾ç‰‡...")
        response = client.images.generate(
            model="dall-e-3",
            prompt=prompt,
            n=1,
            size="1024x1024"
        )

        if not response.data or len(response.data) == 0:
            return {
                'success': False,
                'error': 'no_image',
                'message': 'DALL-Eç”Ÿæˆå¤±è´¥'
            }

        # ä¿å­˜å›¾ç‰‡
        import base64
        image_data = response.data[0]

        if hasattr(image_data, 'b64_json') and image_data.b64_json:
            img_bytes = base64.b64decode(image_data.b64_json)
        elif hasattr(image_data, 'url') and image_data.url:
            img_response = requests.get(image_data.url)
            img_bytes = img_response.content
        else:
            return {
                'success': False,
                'error': 'no_data',
                'message': 'æ— æ³•è·å–å›¾ç‰‡æ•°æ®'
            }

        temp_image = tempfile.NamedTemporaryFile(suffix='.png', delete=False)
        temp_image.write(img_bytes)
        temp_image_path = temp_image.name
        temp_image.close()

        print(f"  [2/2] åˆ›å»ºè§†é¢‘åŠ¨ç”»...")

        # ç¬¬äºŒæ­¥: ä½¿ç”¨FFmpegåˆ›å»ºç®€å•åŠ¨ç”»(ç¼©æ”¾æ•ˆæœ)
        try:
            # åˆ›å»º5ç§’è§†é¢‘,å›¾ç‰‡ç¼“æ…¢æ”¾å¤§
            ffmpeg_cmd = [
                'ffmpeg', '-y',
                '-loop', '1',
                '-i', temp_image_path,
                '-vf', 'scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2,zoompan=z=\'min(zoom+0.0015,1.5)\':d=700:x=\'iw/2-(iw/zoom/2)\':y=\'ih/2-(ih/zoom/2)\':fps=30',
                '-c:v', 'libx264',
                '-t', '5',
                '-pix_fmt', 'yuv420p',
                str(output_path)
            ]

            result = subprocess.run(
                ffmpeg_cmd,
                capture_output=True,
                text=True,
                timeout=60
            )

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_image_path)

            if result.returncode == 0 and Path(output_path).exists():
                file_size = Path(output_path).stat().st_size
                print(f"[æˆåŠŸ] è§†é¢‘å·²ç”Ÿæˆ: {output_path}")
                print(f"  å¤§å°: {file_size} bytes")

                return {
                    'success': True,
                    'file_path': str(output_path),
                    'file_size': file_size,
                    'file_type': 'mp4',
                    'message': 'DALL-Eå›¾ç‰‡ + FFmpegåŠ¨ç”»'
                }
            else:
                os.unlink(temp_image_path)
                return {
                    'success': False,
                    'error': 'ffmpeg_failed',
                    'message': 'FFmpegè§†é¢‘åˆ›å»ºå¤±è´¥'
                }

        except FileNotFoundError:
            os.unlink(temp_image_path)
            return {
                'success': False,
                'error': 'ffmpeg_not_found',
                'message': 'FFmpegæœªå®‰è£…,æ— æ³•åˆ›å»ºè§†é¢‘'
            }
        except Exception as e:
            os.unlink(temp_image_path)
            return {
                'success': False,
                'error': str(e),
                'message': f'è§†é¢‘åˆ›å»ºå¤±è´¥: {str(e)[:100]}'
            }

    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': f"ç”Ÿæˆå¤±è´¥: {str(e)[:100]}"
        }


def generate_video_with_seedance(prompt, output_path):
    """ä½¿ç”¨Seedance 1.5 Pro(ç«å±±å¼•æ“)ç”Ÿæˆè§†é¢‘"""

    try:
        print(f"[Seedance 1.5 Pro] æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
        print(f"  æç¤ºè¯: {prompt[:100]}...")

        import os
        volcano_api_key = os.environ.get('VOLCANO_API_KEY', '')

        if not volcano_api_key:
            return {
                'success': False,
                'error': 'no_api_key',
                'message': 'æœªé…ç½®VOLCANO_API_KEY'
            }

        # ç«å±±å¼•æ“Seedanceè§†é¢‘ç”ŸæˆAPIç«¯ç‚¹ (æ­£ç¡®è·¯å¾„)
        api_url = "https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks"

        headers = {
            'Authorization': f'Bearer {volcano_api_key}',
            'Content-Type': 'application/json'
        }

        # æ„å»ºè¯·æ±‚payload (æŒ‰ç…§å®˜æ–¹æ–‡æ¡£æ ¼å¼)
        payload = {
            "model": "doubao-seedance-1-5-pro-251215",  # Seedance 1.5 Proæœ€æ–°æ¨¡å‹
            "content": [
                {
                    "type": "text",
                    "text": prompt
                }
            ],
            "resolution": "720p",      # åˆ†è¾¨ç‡: 480p/720p/1080p
            "ratio": "16:9",           # å®½é«˜æ¯”: 16:9/4:3/1:1ç­‰
            "duration": 5,             # è§†é¢‘æ—¶é•¿(ç§’): 4-12ç§’
            "watermark": False,        # ä¸æ·»åŠ æ°´å°
            "generate_audio": True,    # ç”ŸæˆéŸ³é¢‘(Seedance 1.5 Proæ–°åŠŸèƒ½)
            "draft": False            # éæ ·ç‰‡æ¨¡å¼,ç”Ÿæˆæ­£å¼è§†é¢‘
        }

        print(f"  [è¯·æ±‚] è°ƒç”¨ç«å±±å¼•æ“Seedance 1.5 Pro API...")
        print(f"  [é…ç½®] åˆ†è¾¨ç‡:720p, æ—¶é•¿:5ç§’, å¸¦éŸ³é¢‘")
        response = requests.post(api_url, json=payload, headers=headers, timeout=60)

        if response.status_code == 200:
            result = response.json()

            # è·å–ä»»åŠ¡ID
            task_id = result.get('id')
            if not task_id:
                return {
                    'success': False,
                    'error': 'no_task_id',
                    'message': 'æœªè¿”å›ä»»åŠ¡ID'
                }

            print(f"  [ä»»åŠ¡ID] {task_id}")
            print(f"  [è½®è¯¢] ç­‰å¾…è§†é¢‘ç”Ÿæˆ...")

            # è½®è¯¢æ£€æŸ¥çŠ¶æ€
            max_attempts = 120  # æœ€å¤šè½®è¯¢120æ¬¡(10åˆ†é’Ÿ)
            import time

            for attempt in range(max_attempts):
                time.sleep(5)  # ç­‰å¾…5ç§’

                # æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
                status_url = f"https://ark.cn-beijing.volces.com/api/v3/contents/generations/tasks/{task_id}"
                status_response = requests.get(status_url, headers=headers, timeout=30)

                if status_response.status_code == 200:
                    status_result = status_response.json()
                    status = status_result.get('status', 'unknown')

                    if status == 'succeeded':
                        # æˆåŠŸ,è·å–è§†é¢‘URL
                        # æ³¨æ„: video_urlåœ¨contentå¯¹è±¡é‡Œé¢
                        content = status_result.get('content', {})
                        video_url = content.get('video_url')
                        if not video_url:
                            return {
                                'success': False,
                                'error': 'no_video_url',
                                'message': 'ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›è§†é¢‘URL'
                            }

                        print(f"  [ä¸‹è½½] æ­£åœ¨ä¸‹è½½è§†é¢‘...")
                        video_response = requests.get(video_url, timeout=120)

                        if video_response.status_code == 200:
                            with open(output_path, 'wb') as f:
                                f.write(video_response.content)

                            file_size = len(video_response.content)
                            print(f"[æˆåŠŸ] è§†é¢‘å·²ä¿å­˜: {output_path}")
                            print(f"  å¤§å°: {file_size} bytes")

                            return {
                                'success': True,
                                'file_path': str(output_path),
                                'file_size': file_size,
                                'file_type': 'mp4',
                                'message': 'Seedance 1.5 Proè§†é¢‘ç”ŸæˆæˆåŠŸ(å«éŸ³é¢‘)'
                            }
                        else:
                            return {
                                'success': False,
                                'error': 'download_failed',
                                'message': f'è§†é¢‘ä¸‹è½½å¤±è´¥: {video_response.status_code}'
                            }

                    elif status == 'failed':
                        error_msg = status_result.get('error_message', 'è§†é¢‘ç”Ÿæˆå¤±è´¥')
                        return {
                            'success': False,
                            'error': 'generation_failed',
                            'message': f'ä»»åŠ¡å¤±è´¥: {error_msg}'
                        }

                    elif status in ['queued', 'running']:
                        if (attempt + 1) % 6 == 0:  # æ¯30ç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                            print(f"  [è½®è¯¢] {attempt+1}/{max_attempts} - çŠ¶æ€: {status}")
                    else:
                        print(f"  [è½®è¯¢] {attempt+1}/{max_attempts} - çŠ¶æ€: {status}")
                else:
                    print(f"  [è­¦å‘Š] æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {status_response.status_code}")

            return {
                'success': False,
                'error': 'timeout',
                'message': 'è§†é¢‘ç”Ÿæˆè¶…æ—¶(10åˆ†é’Ÿ)'
            }
        else:
            # APIè¿”å›é”™è¯¯
            try:
                error_data = response.json()
                error_msg = error_data.get('error', {}).get('message', str(response.text))
            except:
                error_msg = str(response.text)[:200]

            return {
                'success': False,
                'error': f'api_error_{response.status_code}',
                'message': f'APIé”™è¯¯({response.status_code}): {error_msg}'
            }

    except requests.exceptions.Timeout:
        return {
            'success': False,
            'error': 'timeout',
            'message': 'è¯·æ±‚è¶…æ—¶'
        }
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'message': f"ç”Ÿæˆå¤±è´¥: {str(e)[:100]}"
        }


def generate_video_with_gemini_veo(prompt, output_path):
    """ä½¿ç”¨Gemini Veo 3.1ç”Ÿæˆè§†é¢‘"""

    try:
        print(f"[Gemini Veo 3.1] æ­£åœ¨ç”Ÿæˆè§†é¢‘...")
        print(f"  æç¤ºè¯: {prompt[:100]}...")

        # Gemini Veoéœ€è¦Google Cloud API key
        # ä¸åœ¨antigravityä¸‹,éœ€è¦ç›´æ¥ä½¿ç”¨Google API
        import os
        gemini_api_key = os.environ.get('GEMINI_API_KEY', '')

        if not gemini_api_key:
            return {
                'success': False,
                'error': 'no_api_key',
                'message': 'æœªé…ç½®GEMINI_API_KEY (éœ€è¦Google Cloud API key)'
            }

        # Gemini Veo APIç«¯ç‚¹
        # æ³¨æ„: Veoä½¿ç”¨Google's generative-ai SDK
        try:
            from google import genai
            from google.genai import types

            client = genai.Client(api_key=gemini_api_key)

            print(f"  [è¯·æ±‚] è°ƒç”¨Gemini Veo 3.1 API...")
            print(f"  [æç¤º] è§†é¢‘ç”Ÿæˆæ˜¯å¼‚æ­¥æ“ä½œ,å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ...")

            # åˆ›å»ºè§†é¢‘ç”Ÿæˆæ“ä½œ
            operation = client.models.generate_videos(
                model="veo-3.1-generate-preview",
                prompt=prompt,
                config=types.GenerateVideoConfig(
                    duration_seconds=8,  # 8ç§’è§†é¢‘
                    resolution="720p",   # 720påˆ†è¾¨ç‡
                    aspect_ratio="16:9"
                )
            )

            # è½®è¯¢ç›´åˆ°å®Œæˆ
            print(f"  [è½®è¯¢] ç­‰å¾…è§†é¢‘ç”Ÿæˆ...")
            max_attempts = 60  # æœ€å¤šè½®è¯¢60æ¬¡(10åˆ†é’Ÿ)
            import time

            for attempt in range(max_attempts):
                if operation.done:
                    break

                time.sleep(10)  # ç­‰å¾…10ç§’
                print(f"  [è½®è¯¢] {attempt+1}/{max_attempts} - ç”Ÿæˆä¸­...")

            if not operation.done:
                return {
                    'success': False,
                    'error': 'timeout',
                    'message': 'è§†é¢‘ç”Ÿæˆè¶…æ—¶(10åˆ†é’Ÿ)'
                }

            # è·å–ç”Ÿæˆçš„è§†é¢‘
            if hasattr(operation.response, 'generated_videos') and len(operation.response.generated_videos) > 0:
                video = operation.response.generated_videos[0]

                # ä¸‹è½½è§†é¢‘
                if hasattr(video, 'video'):
                    client.files.download(file=video.video)
                    video.video.save(str(output_path))

                    file_size = Path(output_path).stat().st_size
                    print(f"[æˆåŠŸ] è§†é¢‘å·²ä¿å­˜: {output_path}")
                    print(f"  å¤§å°: {file_size} bytes")

                    return {
                        'success': True,
                        'file_path': str(output_path),
                        'file_size': file_size,
                        'file_type': 'mp4',
                        'message': 'Gemini Veo 3.1è§†é¢‘ç”ŸæˆæˆåŠŸ'
                    }

            return {
                'success': False,
                'error': 'no_video',
                'message': 'æœªè¿”å›ç”Ÿæˆçš„è§†é¢‘'
            }

        except ImportError:
            return {
                'success': False,
                'error': 'no_sdk',
                'message': 'éœ€è¦å®‰è£…google-generativeai SDK: pip install google-generativeai'
            }

    except Exception as e:
        error_str = str(e)
        # æ£€æŸ¥æ˜¯å¦æ˜¯API keyé”™è¯¯
        if 'API key' in error_str or 'auth' in error_str.lower():
            return {
                'success': False,
                'error': 'auth_failed',
                'message': 'Gemini API keyéªŒè¯å¤±è´¥'
            }
        else:
            return {
                'success': False,
                'error': str(e),
                'message': f"ç”Ÿæˆå¤±è´¥: {error_str[:100]}"
            }


# ==================== AIè¯„ä»·å‡½æ•° ====================


def ai_evaluate_videos(prompt, video_results):
    """ä½¿ç”¨AIè¯„ä»·ç”Ÿæˆçš„è§†é¢‘"""

    try:
        print(f"\n[AIè¯„ä»·] æ­£åœ¨åˆ†æè§†é¢‘è´¨é‡...")

        client = get_zhipuai_client()
        if not client:
            print("[è­¦å‘Š] æ— æ³•è·å–ZhipuAIå®¢æˆ·ç«¯,è·³è¿‡AIè¯„ä»·")
            return None

        # æ„å»ºè¯„ä»·æç¤º
        evaluation_prompt = f"""è¯·è¯„ä»·ä»¥ä¸‹è§†é¢‘ç”Ÿæˆç»“æœ,æ ¹æ®æç¤ºè¯è´¨é‡å’Œåˆ›æ„è¿›è¡Œè¯„åˆ†æ’åºã€‚

æç¤ºè¯: {prompt}

ç”Ÿæˆçš„è§†é¢‘ç»“æœ:
"""

        for i, result in enumerate(video_results, 1):
            if result['success']:
                evaluation_prompt += f"\n{i}. {result['model_name']}\n"
                evaluation_prompt += f"   - æ–‡ä»¶: {Path(result['file_path']).name}\n"
                evaluation_prompt += f"   - å¤§å°: {result.get('file_size', 0)} bytes\n"
                evaluation_prompt += f"   - ç±»å‹: {result.get('file_type', 'unknown')}\n"
                evaluation_prompt += f"   - è¯´æ˜: {result.get('message', '')}\n"

        evaluation_prompt += """

è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¯„åˆ†(1-10åˆ†):
1. æŠ€æœ¯è´¨é‡(åˆ†è¾¨ç‡ã€æµç•…åº¦)
2. åˆ›æ„è¡¨ç°(æ˜¯å¦ç¬¦åˆæç¤ºè¯)
3. è§†è§‰æ•ˆæœ(è‰²å½©ã€æ„å›¾)

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä»·ç»“æœ,æ ¼å¼å¦‚ä¸‹:
{
  "rankings": [
    {
      "rank": 1,
      "model": "æ¨¡å‹åç§°",
      "score": 85,
      "reasoning": "è¯„ä»·ç†ç”±"
    }
  ],
  "summary": "æ€»ä½“è¯„ä»·"
}
"""

        response = client.chat.completions.create(
            model="glm-4.6",
            messages=[
                {"role": "user", "content": evaluation_prompt}
            ],
            temperature=0.7
        )

        # è§£æAIå“åº”
        ai_response = response.choices[0].message.content

        print(f"\n[AIè¯„ä»·ç»“æœ]")
        print(ai_response)

        # å°è¯•æå–JSON
        try:
            # æŸ¥æ‰¾JSONä»£ç å—
            if '```json' in ai_response:
                json_start = ai_response.find('```json') + 7
                json_end = ai_response.find('```', json_start)
                json_str = ai_response[json_start:json_end].strip()
            elif '```' in ai_response:
                json_start = ai_response.find('```') + 3
                json_end = ai_response.find('```', json_start)
                json_str = ai_response[json_start:json_end].strip()
            else:
                # å°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª{å’Œæœ€åä¸€ä¸ª}
                json_start = ai_response.find('{')
                json_end = ai_response.rfind('}') + 1
                json_str = ai_response[json_start:json_end]

            evaluation = json.loads(json_str)
            return evaluation

        except (json.JSONDecodeError, ValueError) as e:
            print(f"[è­¦å‘Š] æ— æ³•è§£æAIå“åº”ä¸ºJSON: {e}")
            return {
                'summary': ai_response,
                'rankings': []
            }

    except Exception as e:
        print(f"[é”™è¯¯] AIè¯„ä»·å¤±è´¥: {e}")
        return None


def generate_html_report(prompt, video_results, ai_evaluation, output_path):
    """ç”ŸæˆHTMLå¯¹æ¯”æŠ¥å‘Š"""

    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    html_content = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è§†é¢‘ç”Ÿæˆæ¨¡å‹å¯¹æ¯” - {prompt[:50]}</title>
    <style>
        * {{
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }}

        body {{
            font-family: 'Microsoft YaHei', Arial, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            min-height: 100vh;
        }}

        .container {{
            max-width: 1600px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
        }}

        h1 {{
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 2.5em;
        }}

        .subtitle {{
            text-align: center;
            color: #666;
            margin-bottom: 40px;
            font-size: 1.1em;
        }}

        .prompt-section {{
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
        }}

        .prompt-text {{
            font-size: 1.1em;
            line-height: 1.6;
        }}

        .model-section {{
            margin-bottom: 40px;
            border: 2px solid #e0e0e0;
            border-radius: 15px;
            padding: 25px;
            background: #f9f9f9;
        }}

        .model-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 20px;
            padding-bottom: 15px;
            border-bottom: 2px solid #ddd;
        }}

        .model-title {{
            font-size: 1.8em;
            color: #333;
            font-weight: bold;
        }}

        .model-meta {{
            color: #666;
            font-size: 0.9em;
        }}

        .video-container {{
            position: relative;
            background: black;
            border-radius: 10px;
            overflow: hidden;
            margin-bottom: 15px;
        }}

        .video-container video,
        .video-container img {{
            width: 100%;
            height: auto;
            display: block;
        }}

        .rank-badge {{
            position: absolute;
            top: 15px;
            left: 15px;
            background: linear-gradient(135deg, #FFD700 0%, #FFA500 100%);
            color: white;
            padding: 10px 20px;
            border-radius: 25px;
            font-weight: bold;
            font-size: 1.2em;
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
        }}

        .rank-1 {{ background: linear-gradient(135deg, #FFD700 0%, #FFA500 100%); }}
        .rank-2 {{ background: linear-gradient(135deg, #C0C0C0 0%, #808080 100%); }}
        .rank-3 {{ background: linear-gradient(135deg, #CD7F32 0%, #8B4513 100%); }}

        .video-info {{
            padding: 15px;
            background: white;
            border-radius: 8px;
        }}

        .info-row {{
            display: flex;
            justify-content: space-between;
            padding: 8px 0;
            border-bottom: 1px solid #eee;
        }}

        .info-row:last-child {{
            border-bottom: none;
        }}

        .info-label {{
            font-weight: bold;
            color: #555;
        }}

        .info-value {{
            color: #333;
        }}

        .status-success {{
            color: #4caf50;
            font-weight: bold;
        }}

        .status-error {{
            color: #f44336;
            font-weight: bold;
        }}

        .ai-evaluation {{
            background: #e8f5e9;
            border-left: 5px solid #4caf50;
            padding: 20px;
            margin-top: 30px;
            border-radius: 10px;
        }}

        .ai-evaluation h2 {{
            color: #2e7d32;
            margin-bottom: 15px;
        }}

        .ranking-item {{
            background: white;
            padding: 15px;
            margin-bottom: 10px;
            border-radius: 8px;
            border-left: 4px solid #4caf50;
        }}

        .ranking-header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 10px;
        }}

        .ranking-model {{
            font-weight: bold;
            font-size: 1.1em;
            color: #333;
        }}

        .ranking-score {{
            background: #4caf50;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-weight: bold;
        }}

        .ranking-reason {{
            color: #666;
            line-height: 1.6;
        }}

        footer {{
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 1px solid #ddd;
            color: #666;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¬ è§†é¢‘ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æµ‹è¯•</h1>
        <p class="subtitle">ç”Ÿæˆæ—¶é—´: {timestamp}</p>

        <div class="prompt-section">
            <h2>ğŸ“ æç¤ºè¯</h2>
            <p class="prompt-text">{prompt}</p>
        </div>
"""

    # æ·»åŠ AIè¯„ä»·(å¦‚æœæœ‰)
    if ai_evaluation and 'rankings' in ai_evaluation:
        html_content += """
        <div class="ai-evaluation">
            <h2>ğŸ¤– AIè¯„ä»·ä¸æ’å</h2>
"""

        # åˆ›å»ºæ’åæ˜ å°„
        rank_map = {}
        for ranking in ai_evaluation['rankings']:
            rank_map[ranking['model']] = ranking

        for ranking in ai_evaluation['rankings']:
            html_content += f"""
            <div class="ranking-item">
                <div class="ranking-header">
                    <span class="ranking-model">#{ranking['rank']} {ranking['model']}</span>
                    <span class="ranking-score">{ranking.get('score', 'N/A')}åˆ†</span>
                </div>
                <div class="ranking-reason">{ranking.get('reasoning', '')}</div>
            </div>
"""

        if 'summary' in ai_evaluation:
            html_content += f"""
            <p style="margin-top: 15px; color: #2e7d32; font-style: italic;">
                <strong>æ€»ç»“:</strong> {ai_evaluation['summary']}
            </p>
"""

        html_content += """
        </div>
"""

    # æ·»åŠ è§†é¢‘ç»“æœ
    for result in video_results:
        model_name = result['model_name']

        # ç¡®å®šæ’å
        rank_badge = ""
        if ai_evaluation and 'rankings' in ai_evaluation:
            for ranking in ai_evaluation['rankings']:
                if ranking['model'] == model_name:
                    rank_class = f"rank-{ranking['rank']}" if ranking['rank'] <= 3 else "rank-other"
                    rank_badge = f'<div class="rank-badge {rank_class}">#{ranking["rank"]}</div>'
                    break

        html_content += f"""
        <div class="model-section">
            <div class="model-header">
                <div class="model-title">{model_name}</div>
                <div class="model-meta">
                    æä¾›å•†: {result['provider']} |
                    ç±»å‹: {result['type']}
                </div>
            </div>
"""

        if result['success']:
            file_ext = Path(result['file_path']).suffix.lower()
            is_video = file_ext in ['.mp4', '.webm', '.mov']
            is_gif = file_ext == '.gif'
            is_image = file_ext in ['.png', '.jpg', '.jpeg']

            html_content += f"""
            <div class="video-container" style="position: relative;">
                {rank_badge}
"""

            if is_video:
                html_content += f"""
                <video controls>
                    <source src="{Path(result['file_path']).name}" type="video/mp4">
                    æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè§†é¢‘æ’­æ”¾
                </video>
"""
            elif is_gif:
                html_content += f"""
                <img src="{Path(result['file_path']).name}" alt="{model_name}">
"""
            elif is_image:
                html_content += f"""
                <img src="{Path(result['file_path']).name}" alt="{model_name}">
                <p style="position: absolute; bottom: 10px; left: 10px; background: rgba(0,0,0,0.7); color: white; padding: 5px 10px; border-radius: 5px; font-size: 0.9em;">
                    âš ï¸ å›¾ç‰‡æ ¼å¼(éè§†é¢‘)
                </p>
"""
            else:
                html_content += f"""
                <p style="padding: 40px; text-align: center; color: white;">
                    æ–‡ä»¶æ ¼å¼: {file_ext.upper()}
                </p>
"""

            html_content += """
            </div>
            <div class="video-info">
"""

            # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
            html_content += f"""
                <div class="info-row">
                    <span class="info-label">çŠ¶æ€:</span>
                    <span class="info-value status-success">âœ“ æˆåŠŸ</span>
                </div>
                <div class="info-row">
                    <span class="info-label">æ–‡ä»¶:</span>
                    <span class="info-value">{Path(result['file_path']).name}</span>
                </div>
                <div class="info-row">
                    <span class="info-label">å¤§å°:</span>
                    <span class="info-value">{result.get('file_size', 0):,} bytes</span>
                </div>
                <div class="info-row">
                    <span class="info-label">ç±»å‹:</span>
                    <span class="info-value">{result.get('file_type', 'unknown').upper()}</span>
                </div>
                <div class="info-row">
                    <span class="info-label">è¯´æ˜:</span>
                    <span class="info-value">{result.get('message', '')}</span>
                </div>
"""

            html_content += """
            </div>
        """
        else:
            html_content += f"""
            <div class="video-info">
                <div class="info-row">
                    <span class="info-label">çŠ¶æ€:</span>
                    <span class="info-value status-error">âœ— å¤±è´¥</span>
                </div>
                <div class="info-row">
                    <span class="info-label">é”™è¯¯:</span>
                    <span class="info-value">{result.get('message', 'æœªçŸ¥é”™è¯¯')}</span>
                </div>
            </div>
        """

        html_content += """
        </div>
"""

    # é¡µè„š
    html_content += f"""
        <footer>
            <p>æµ‹è¯•å®Œæˆæ—¶é—´: {timestamp}</p>
            <p>è§†é¢‘ç”Ÿæˆå¯¹æ¯”å·¥å…· | æ”¯æŒå¤šç§è§†é¢‘ç”Ÿæˆæ¨¡å‹</p>
        </footer>
    </div>
</body>
</html>
"""

    # ä¿å­˜HTML
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(html_content)

    return output_path


def load_progress(output_dir):
    """åŠ è½½ä¹‹å‰çš„è¿›åº¦"""
    progress_file = output_dir / "video_generation_progress.json"

    if progress_file.exists():
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress = json.load(f)
                return progress
        except:
            pass

    return None


def save_progress(output_dir, prompt, completed_models):
    """ä¿å­˜è¿›åº¦"""
    progress_file = output_dir / "video_generation_progress.json"

    progress = {
        'timestamp': datetime.now().strftime("%Y%m%d_%H%M%S"),
        'prompt': prompt,
        'completed_models': completed_models
    }

    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump(progress, f, ensure_ascii=False, indent=2)


def main():
    """ä¸»å‡½æ•°"""

    print("="*80)
    print("è§†é¢‘ç”Ÿæˆæ¨¡å‹å¯¹æ¯”å·¥å…·")
    print("="*80)
    print()

    # è·å–ç”¨æˆ·è¾“å…¥
    prompt = input("è¯·è¾“å…¥è§†é¢‘ç”Ÿæˆä¸»é¢˜/æç¤ºè¯: ").strip()

    if not prompt:
        print("[é”™è¯¯] æç¤ºè¯ä¸èƒ½ä¸ºç©º")
        return

    print()
    print(f"[æç¤ºè¯] {prompt}")
    print()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    script_dir = Path(__file__).parent
    output_dir = script_dir / "video_comparison_output"
    output_dir.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    print(f"[è¾“å‡ºç›®å½•] {output_dir}")
    print()

    # å‡†å¤‡æ¨¡å‹åˆ—è¡¨
    enabled_models = []
    for model_id, config in VIDEO_GENERATION_MODELS.items():
        if config['enabled']:
            enabled_models.append({
                'id': model_id,
                'name': config['name'],
                'provider': config['provider'],
                'type': config['type']
            })

    print(f"[ä¿¡æ¯] å°†æµ‹è¯• {len(enabled_models)} ä¸ªè§†é¢‘ç”Ÿæˆæ¨¡å‹")
    for i, model in enumerate(enabled_models, 1):
        print(f"  {i}. {model['name']} ({model['provider']})")
    print()

    # åŠ è½½ä¹‹å‰çš„è¿›åº¦
    previous_progress = load_progress(output_dir)
    completed_models = set()

    if previous_progress:
        print(f"[æ–­ç‚¹ç»­ä¼ ] æ‰¾åˆ°ä¹‹å‰çš„è¿›åº¦")
        print(f"  æç¤ºè¯: {previous_progress.get('prompt', '')[:50]}...")
        print(f"  æ—¶é—´: {previous_progress.get('timestamp', '')}")
        print(f"  å·²å®Œæˆ: {len(previous_progress.get('completed_models', []))} ä¸ªæ¨¡å‹")
        print()

        # æ£€æŸ¥æç¤ºè¯æ˜¯å¦ç›¸åŒ
        if previous_progress.get('prompt') == prompt:
            completed_models = set(previous_progress.get('completed_models', []))
            print(f"[æ–­ç‚¹ç»­ä¼ ] å°†è·³è¿‡å·²å®Œæˆçš„ {len(completed_models)} ä¸ªæ¨¡å‹")
        else:
            print(f"[æ–°ä»»åŠ¡] æç¤ºè¯å·²æ›´æ”¹,é‡æ–°å¼€å§‹")
            completed_models = set()
    else:
        print(f"[æ–°ä»»åŠ¡] æœªæ‰¾åˆ°ä¹‹å‰çš„è¿›åº¦")
    print()

    # ç”Ÿæˆè§†é¢‘
    print("="*80)
    print("å¼€å§‹ç”Ÿæˆè§†é¢‘...")
    print("="*80)
    print()

    results = []
    completed_count = 0
    skipped_count = 0

    for i, model in enumerate(enabled_models, 1):
        model_id = model['id']
        model_name = model['name']

        # æ–­ç‚¹ç»­ä¼ : è·³è¿‡å·²å®Œæˆçš„æ¨¡å‹
        if model_id in completed_models:
            print(f"[{i}/{len(enabled_models)}] {model_name}")
            print(f"  [è·³è¿‡] å·²ç”Ÿæˆ,è·³è¿‡")
            print()

            # å°è¯•åŠ è½½ä¹‹å‰çš„ç»“æœ
            safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '')

            # æŸ¥æ‰¾å·²ç”Ÿæˆçš„æ–‡ä»¶
            existing_files = list(output_dir.glob(f"{safe_name}_*.*"))
            if existing_files:
                latest_file = max(existing_files, key=lambda p: p.stat().st_mtime)
                file_size = latest_file.stat().st_size

                # ç¡®å®šæ–‡ä»¶ç±»å‹
                file_ext = latest_file.suffix.lower()
                file_type = file_ext[1:] if file_ext else 'unknown'

                result = {
                    'success': True,
                    'file_path': str(latest_file),
                    'file_size': file_size,
                    'file_type': file_type,
                    'message': f'ä½¿ç”¨å·²ç”Ÿæˆçš„ {file_type.upper()} æ–‡ä»¶'
                }
                skipped_count += 1
            else:
                result = {
                    'success': False,
                    'error': 'file_not_found',
                    'message': 'ä¹‹å‰ç”Ÿæˆçš„æ–‡ä»¶æœªæ‰¾åˆ°,éœ€è¦é‡æ–°ç”Ÿæˆ'
                }
                # ä»completedé›†åˆä¸­ç§»é™¤,ä»¥ä¾¿é‡æ–°ç”Ÿæˆ
                completed_models.discard(model_id)

            result['model_id'] = model_id
            result['model_name'] = model_name
            result['provider'] = model['provider']
            result['type'] = model['type']

            results.append(result)
            continue

        print(f"[{i}/{len(enabled_models)}] {model_name}")
        print(f"  æä¾›å•†: {model['provider']}")
        print(f"  ç±»å‹: {model['type']}")

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        safe_name = model_name.replace(' ', '_').replace('(', '').replace(')', '')
        output_path = output_dir / f"{safe_name}_{timestamp}.mp4"

        # è°ƒç”¨å¯¹åº”çš„ç”Ÿæˆå‡½æ•°
        if model_id == 'dalle-animation':
            result = generate_video_with_dalle_first(prompt, output_path)
        elif model_id == 'seedance':
            result = generate_video_with_seedance(prompt, output_path)
        elif model_id == 'gemini-veo':
            result = generate_video_with_gemini_veo(prompt, output_path)
        else:
            result = {
                'success': False,
                'error': 'not_implemented',
                'message': f'{model_name} æš‚æœªå®ç°(è§†é¢‘ç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­)'
            }

        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        result['model_id'] = model_id
        result['model_name'] = model_name
        result['provider'] = model['provider']
        result['type'] = model['type']

        results.append(result)

        status = "[OK] æˆåŠŸ" if result['success'] else "[FAIL] å¤±è´¥"
        print(f"  {status} {result.get('message', '')}")
        print()

        # å¦‚æœæˆåŠŸ,æ·»åŠ åˆ°å·²å®Œæˆåˆ—è¡¨
        if result['success']:
            completed_models.add(model_id)
            completed_count += 1

    # ä¿å­˜è¿›åº¦
    save_progress(output_dir, prompt, list(completed_models))

    # AIè¯„ä»·
    successful_results = [r for r in results if r['success']]

    if successful_results:
        print("="*80)
        print("AIè¯„ä»·è§†é¢‘è´¨é‡...")
        print("="*80)

        ai_evaluation = ai_evaluate_videos(prompt, successful_results)
    else:
        ai_evaluation = None

    # ç”ŸæˆHTMLæŠ¥å‘Š
    print()
    print("[ç”Ÿæˆ] HTMLå¯¹æ¯”æŠ¥å‘Š...")

    html_path = output_dir / f"video_comparison_{timestamp}.html"
    generate_html_report(prompt, results, ai_evaluation, html_path)

    print(f"[å®Œæˆ] HTMLæŠ¥å‘Š: {html_path}")

    # ç»Ÿè®¡
    print()
    print("="*80)
    print("æµ‹è¯•ç»Ÿè®¡")
    print("="*80)
    print(f"æ€»æ¨¡å‹æ•°: {len(enabled_models)}")
    print(f"æœ¬æ¬¡æ–°ç”Ÿæˆ: {completed_count}")
    print(f"è·³è¿‡å·²å®Œæˆ: {skipped_count}")
    print(f"æˆåŠŸç”Ÿæˆ: {len(successful_results)}")
    print(f"å¤±è´¥: {len(enabled_models) - len(successful_results)}")
    print()

    # è‡ªåŠ¨æ‰“å¼€HTMLæŠ¥å‘Š
    try:
        import subprocess
        subprocess.Popen(['start', '', str(html_path)], shell=True)
        print(f"[ä¿¡æ¯] å·²åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€HTMLæŠ¥å‘Š")
    except:
        print(f"[æç¤º] è¯·æ‰‹åŠ¨æ‰“å¼€: {html_path}")

    print()
    print("="*80)
    print("å®Œæˆ!")
    print("="*80)


if __name__ == "__main__":
    main()
