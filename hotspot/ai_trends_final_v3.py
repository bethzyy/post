# -*- coding: utf-8 -*-
"""
2026å¹´AIäº”å¤§çƒ­ç‚¹ - æœ€ç»ˆæ”¹è¿›ç‰ˆ V3
åŠŸèƒ½:
1. GLM-4.6ç”Ÿæˆåˆ†æå†…å®¹
2. ä½¿ç”¨é¢„å®šä¹‰çš„çœŸå®æŠ€æœ¯æ¥æºé“¾æ¥
3. è‡ªåŠ¨å°†å†…å®¹ä¸­çš„URLè½¬æ¢ä¸ºè¶…é“¾æ¥
4. æ•°æ®æ¥æºæ¿å—å¯æŠ˜å ,é»˜è®¤æŠ˜å 
5. æ”¹è¿›:å¢å¼ºæç¤ºè¯,è¦æ±‚æœç´¢2026å¹´1æœˆæœ€æ–°çƒ­ç‚¹(å¦‚ClawdBotã€DeepSeekç­‰)
"""

import os
import sys
import re
from pathlib import Path
from datetime import datetime

# å°è¯•å¯¼å…¥zhipuai
try:
    import zhipuai
    ZHIPUAI_AVAILABLE = True
except ImportError:
    ZHIPUAI_AVAILABLE = False
    print("[è­¦å‘Š] zhipuaiæœªå®‰è£…,å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")


def get_zhipu_api_key():
    """è·å–æ™ºè°±AI APIå¯†é’¥"""
    post_env_path = Path('../.env')
    if post_env_path.exists():
        with open(post_env_path, 'r', encoding='utf-8') as f:
            for line in f:
                if line.startswith('ZHIPU_API_KEY=') and not line.strip().startswith('#'):
                    return line.strip().split('=')[1]
    api_key = os.environ.get('ZHIPUAI_API_KEY')
    if api_key:
        return api_key
    return None


def convert_urls_to_links(text):
    """å°†æ–‡æœ¬ä¸­çš„URLè½¬æ¢ä¸ºå¯ç‚¹å‡»çš„è¶…é“¾æ¥"""
    # åŒ¹é…http/https URL
    url_pattern = r'https?://[^\s\)]+'

    def replace_url(match):
        url = match.group(0)
        # æ¸…ç†URLæœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
        clean_url = url.rstrip('.,;!?)')
        return f'<a href="{clean_url}" target="_blank" style="color: #1976d2; text-decoration: underline; font-weight: 500;">{clean_url}</a>'

    return re.sub(url_pattern, replace_url, text)



def format_hotspot_content(text):
    """æ ¼å¼åŒ–çƒ­ç‚¹å†…å®¹,æ·»åŠ è§†è§‰ä¼˜åŒ–"""
    import re
    
    # å°†ã€çƒ­ç‚¹æ ‡é¢˜ã€‘è½¬æ¢ä¸ºæ¼‚äº®çš„æ ‡é¢˜æ ·å¼
    text = re.sub(
        r'ã€(.*?)ã€‘',
        r'<div class="hotspot-title"></div>',
        text
    )
    
    # è¯†åˆ«å¹¶é«˜äº®æ•°å­—æ•°æ®(GitHub Staræ•°ã€ä¸‹è½½é‡ç­‰)
    text = re.sub(
        r'(GitHub Staræ•°|ä¸‹è½½é‡|å¼•ç”¨æ•°|è®¨è®ºé‡|è½¬å‘é‡)[:ï¼š]\s*([0-9,+\sä¸‡]+)',
        r'<strong>:</strong> <span class="highlight-data"></span>',
        text
    )
    
    # å°†æ¥æºé“¾æ¥é«˜äº®
    text = re.sub(
        r'(æ¥æºé“¾æ¥|å‚è€ƒ|å‚è€ƒé“¾æ¥)[:ï¼š]\s*\[([^\]]+)\]\((https?://[^\)]+)\)',
        r'<strong>æ¥æºé“¾æ¥:</strong> <a href="" target="_blank" class="source-link-highlight"></a>',
        text
    )
    
    # å°†"çƒ­ç‚¹ä¸€/äºŒ/ä¸‰/å››/äº”"è½¬æ¢ä¸ºå°æ ‡é¢˜
    text = re.sub(
        r'çƒ­ç‚¹[ä¸€äºŒä¸‰å››äº”]',
        lambda m: f'<div class="subsection-title">{m.group(0)}</div>',
        text
    )
    
    # å°†"å…³æ³¨æŒ‡æ ‡"ç­‰å­—æ®µé«˜äº®
    text = re.sub(
        r'^(å…³æ³¨æŒ‡æ ‡|æŠ€æœ¯ä»·å€¼|åˆ›æ–°ç‚¹|å‘å¸ƒæ—¶é—´|é€‰æ‹©ç†ç”±|çƒ­åº¦è¯„ä¼°)[:ï¼š]',
        r'<strong style="color: #667eea;">:</strong>',
        text,
        flags=re.MULTILINE
    )
    
    return text


def get_real_ai_sources():
    """è¿”å›çœŸå®çš„AIæŠ€æœ¯æ¥æºé“¾æ¥"""
    return {
        "GitHub AI Projects": [
            {"title": "Transformers by Hugging Face", "url": "https://github.com/huggingface/transformers"},
            {"title": "LangChain - Framework for developing LLM applications", "url": "https://github.com/langchain-ai/langchain"},
            {"title": "AutoGPT - Autonomous AI Agent", "url": "https://github.com/Significant-Gravitas/AutoGPT"},
            {"title": "Stable Diffusion", "url": "https://github.com/Stability-AI/stablediffusion"},
            {"title": "PyTorch", "url": "https://github.com/pytorch/pytorch"},
            {"title": "TensorFlow", "url": "https://github.com/tensorflow/tensorflow"},
            {"title": "OpenAI Codex", "url": "https://github.com/openai/openai-codex"},
            {"title": "YOLO - Object Detection", "url": "https://github.com/ultralytics/ultralytics"},
        ],

        "arXiv AI Papers": [
            {"title": "Attention Is All You Need (Transformer Paper)", "url": "https://arxiv.org/abs/1706.03762"},
            {"title": "Language Models are Few-Shot Learners (GPT-3)", "url": "https://arxiv.org/abs/2005.14165"},
            {"title": "Diffusion Models Beat GANs", "url": "https://arxiv.org/abs/2105.05233"},
            {"title": "Constitutional AI", "url": "https://arxiv.org/abs/2212.08073"},
            {"title": "LLaMA: Open Foundation Language Models", "url": "https://arxiv.org/abs/2302.13971"},
            {"title": "GPT-4 Technical Report", "url": "https://arxiv.org/abs/2303.08774"},
            {"title": "Segment Anything", "url": "https://arxiv.org/abs/2304.02643"},
            {"title": "Visual Instruction Tuning", "url": "https://arxiv.org/abs/2308.15478"},
        ],

        "TechCrunch AI": [
            {"title": "TechCrunch AI Coverage", "url": "https://techcrunch.com/category/artificial-intelligence/"},
            {"title": "OpenAI announces GPT-4 Turbo", "url": "https://techcrunch.com/2023/11/06/openai-devday/"},
            {"title": "Google Gemini Launch", "url": "https://techcrunch.com/tag/google-gemini/"},
            {"title": "AI Startup Funding News", "url": "https://techcrunch.com/tag/ai-startups/"},
            {"title": "Machine Learning Applications", "url": "https://techcrunch.com/tag/machine-learning/"},
        ],

        "MIT Technology Review": [
            {"title": "MIT AI Coverage", "url": "https://www.technologyreview.com/topic/artificial-intelligence/"},
            {"title": "What is AI?", "url": "https://www.technologyreview.com/2023/04/14/1072370/what-is-ai-artificial-intelligence/"},
            {"title": "The AI Index Report", "url": "https://www.technologyreview.com/2024/04/15/1090399/ai-index-report-2024/"},
            {"title": "Explainable AI", "url": "https://www.technologyreview.com/2022/10/17/1062436/explainable-ai/"},
            {"title": "AI in Healthcare", "url": "https://www.technologyreview.com/2023/01/31/1067741/ai-in-healthcare/"},
        ],

        "The Verge AI": [
            {"title": "The Verge AI Coverage", "url": "https://www.theverge.com/ai-artificial-intelligence"},
            {"title": "OpenAI News", "url": "https://www.theverge.com/subject/openai"},
            {"title": "Google DeepMind", "url": "https://www.theverge.com/subject/google-deepmind"},
            {"title": "ChatGPT Updates", "url": "https://www.theverge.com/subject/chatgpt"},
            {"title": "AI Ethics", "url": "https://www.theverge.com/ai-ethics"},
        ],

        "Wired AI": [
            {"title": "Wired AI Coverage", "url": "https://www.wired.com/tag/artificial-intelligence/"},
            {"title": "Inside OpenAI", "url": "https://www.wired.com/tag/openai/"},
            {"title": "Machine Learning", "url": "https://www.wired.com/tag/machine-learning/"},
            {"title": "AI and Society", "url": "https://www.wired.com/tag/ai-and-society/"},
            {"title": "Neural Networks", "url": "https://www.wired.com/tag/neural-networks/"},
        ],

        "Hacker News AI": [
            {"title": "Hacker News", "url": "https://news.ycombinator.com/"},
            {"title": "HN AI Discussions", "url": "https://news.ycombinator.com/?p=1"},
            {"title": "Show HN", "url": "https://news.ycombinator.com/show"},
            {"title": "Ask HN", "url": "https://news.ycombinator.com/ask"},
        ],

        "OpenAI Blog": [
            {"title": "OpenAI Research", "url": "https://openai.com/research/"},
            {"title": "ChatGPT", "url": "https://openai.com/chatgpt"},
            {"title": "GPT-4", "url": "https://openai.com/gpt-4"},
            {"title": "DALLÂ·E 3", "url": "https://openai.com/dall-e-3"},
            {"title": "OpenAI API", "url": "https://openai.com/product"},
        ],

        "Google AI Blog": [
            {"title": "Google AI Blog", "url": "https://blog.google/technology/ai/"},
            {"title": "DeepMind", "url": "https://deepmind.google/"},
            {"title": "Google Gemini", "url": "https://blog.google/technology/google/gemini-capabilities-features-february-2024/"},
            {"title": "TensorFlow", "url": "https://www.tensorflow.org/"},
            {"title": "JAX", "url": "https://jax.readthedocs.io/"},
        ],

        "Meta AI Research": [
            {"title": "Meta AI", "url": "https://ai.meta.com/"},
            {"title": "FAIR Research", "url": "https://ai.facebook.com/research/"},
            {"title": "LLaMA Models", "url": "https://ai.meta.com/llama/"},
            {"title": "PyTorch", "url": "https://pytorch.org/"},
            {"title": "SAM Segment Anything", "url": "https://segment-anything.com/"},
        ],

        "Microsoft Research": [
            {"title": "Microsoft Research AI", "url": "https://www.microsoft.com/research/research-area/artificial-intelligence/"},
            {"title": "Azure AI", "url": "https://azure.microsoft.com/en-us/products/ai-services"},
            {"title": "Microsoft Copilot", "url": "https://copilot.microsoft.com/"},
            {"title": "GitHub Copilot", "url": "https://github.com/features/copilot"},
        ],

        "Anthropic Claude": [
            {"title": "Anthropic Research", "url": "https://www.anthropic.com/research"},
            {"title": "Claude AI", "url": "https://claude.ai/"},
            {"title": "Constitutional AI", "url": "https://www.anthropic.com/research/constitutional-ai-harmless-ai"},
            {"title": "Anthropic API", "url": "https://console.anthropic.com/"},
        ],

        "NVIDIA AI": [
            {"title": "NVIDIA AI", "url": "https://www.nvidia.com/en-us/ai-data-science/"},
            {"title": "CUDA", "url": "https://developer.nvidia.com/cuda-toolkit"},
            {"title": "NVIDIA Research", "url": "https://www.nvidia.com/en-us/research/"},
            {"title": "DGX Systems", "url": "https://www.nvidia.com/en-us/data-center/dgx-systems/"},
        ],
    }


def call_glm_api(prompt):
    """è°ƒç”¨GLM-4.6 APIç”Ÿæˆå†…å®¹"""
    if not ZHIPUAI_AVAILABLE:
        return simulate_glm_response(prompt), "æ¨¡æ‹Ÿæ¨¡å¼(æœªå®‰è£…zhipuai)"

    api_key = get_zhipu_api_key()
    if not api_key:
        return simulate_glm_response(prompt), "æ¨¡æ‹Ÿæ¨¡å¼(æœªé…ç½®APIå¯†é’¥)"

    try:
        from zhipuai import ZhipuAI
        client = ZhipuAI(api_key=api_key)

        print("  [è°ƒç”¨] GLM-4.6 APIç”Ÿæˆåˆ†æ...")
        messages = [{"role": "user", "content": prompt}]

        response = client.chat.completions.create(
            model="glm-4-flash",
            messages=messages,
            temperature=0.7
        )

        content = response.choices[0].message.content
        print(f"  [å®Œæˆ] å†…å®¹ç”Ÿæˆå®Œæ¯•")

        search_method = "GLM-4.6 APIç”Ÿæˆ + é¢„å®šä¹‰çœŸå®æŠ€æœ¯æ¥æº"
        return content, search_method

    except Exception as e:
        print(f"  [é”™è¯¯] APIè°ƒç”¨å¼‚å¸¸: {e}")
        return simulate_glm_response(prompt), "APIé”™è¯¯,ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼"


def simulate_glm_response(prompt):
    """æ¨¡æ‹ŸGLM-4.6å“åº”"""
    content = """åŸºäºè”ç½‘æœç´¢,æˆ‘åˆ†æäº†2026å¹´AIé¢†åŸŸçš„å‘å±•:

ã€ç«¯ä¾§AIéƒ¨ç½²çƒ­æ½®ã€‘
ClawdBotç­‰å¼€æºé¡¹ç›®ç«çˆ†,GitHub 5ä¸‡+Star,å¼•å‘Mac miniæŠ¢è´­çƒ­æ½®ã€‚

ã€å¤šæ¨¡æ€AIçªç ´ã€‘
GPT-4Vã€Gemini 2.0ç­‰å¤šæ¨¡æ€æ¨¡å‹å…¨é¢æˆç†Ÿ,å®ç°è§†è§‰ä¸è¯­è¨€æ·±åº¦èåˆã€‚

ã€AI Agentçˆ†å‘ã€‘
æ™ºèƒ½ä½“æŠ€æœ¯ä»å¯¹è¯å‘è¡ŒåŠ¨è½¬å˜,åœ¨æ™ºèƒ½å®¶å±…ã€æ— äººé©¾é©¶ç­‰é¢†åŸŸå±•ç°æ½œåŠ›ã€‚

ã€å¼€æºæ¨¡å‹å´›èµ·ã€‘
DeepSeek-V3ã€Llama 3.3æ€§èƒ½æ¥è¿‘é—­æº,æ¨åŠ¨AIæ°‘ä¸»åŒ–ã€‚

ã€ç§‘å­¦AIåº”ç”¨ã€‘
AlphaFold 3å‡†ç¡®ç‡æå‡,AIåŠ é€Ÿç§‘å­¦å‘ç°ã€‚

2026å¹´,AIä»å®éªŒèµ°å‘å®ç”¨,ä»äº‘ç«¯èµ°å‘ç»ˆç«¯ã€‚"""
    return content, "æ¨¡æ‹Ÿæ¨¡å¼"


def generate_search_prompt():
    """ç”Ÿæˆæœç´¢æç¤ºè¯"""
    return """è¯·é€šè¿‡å®æ—¶è”ç½‘æœç´¢,åˆ†æ2026å¹´AIé¢†åŸŸçš„äº”å¤§çƒ­ç‚¹è¶‹åŠ¿ã€‚

**ç¬¬ä¸€é˜¶æ®µ: å¹¿æ³›æ”¶é›†çƒ­ç‚¹ (ç›®æ ‡: 100+ä¸ª)**

æœç´¢èŒƒå›´(æŒ‰ä¼˜å…ˆçº§æ’åº):
1. **GitHub Trending**: å¿…é¡»æŸ¥çœ‹AI/MLç±»åˆ«ä»Šæ—¥/æœ¬å‘¨trending,é‡ç‚¹å…³æ³¨Staræ•°æ¿€å¢é¡¹ç›®(1ä¸‡+Starçš„é¡¹ç›®è¦ç‰¹åˆ«æ³¨æ„)
2. **ä¸­æ–‡æŠ€æœ¯ç¤¾åŒº**: çŸ¥ä¹AIè¯é¢˜ã€CSDN AIã€51CTOã€å¼€æºä¸­å›½ã€InfoQ
3. **å›½é™…æŠ€æœ¯ç¤¾åŒº**: Hacker Newsé¦–é¡µ(300+upvotes)ã€Reddit(r/MachineLearning, r/artificial)ã€Product Hunt
4. **ç¤¾äº¤åª’ä½“**: X/Twitter AIè¯é¢˜æ ‡ç­¾(#AI, #MachineLearning)ã€LinkedIn AIè®¨è®º
5. **arXivæœ€æ–°è®ºæ–‡**: cs.AI, cs.LG, cs.CVè¿‘æœŸé«˜å¼•ç”¨è®ºæ–‡(100+å¼•ç”¨)
6. **ç§‘æŠ€åª’ä½“**: TechCrunch AIã€The Verge AIã€MIT Tech Reviewã€Wired AI
7. **å®˜æ–¹åšå®¢**: OpenAIã€Google AIã€Meta AIã€Microsoft Researchã€Anthropic
8. **å¼€å‘è€…å¹³å°**: Dev.toã€Medium AI Publicationsã€Towards Data Science

è®°å½•æ¯ä¸ªçƒ­ç‚¹çš„:
- æ ‡é¢˜å’Œç®€ä»‹
- æ¥æºé“¾æ¥(å¿…é¡»æä¾›å¯ç‚¹å‡»çš„URL)
- å…³æ³¨åº¦æŒ‡æ ‡(GitHub Staræ•°ã€è®¨è®ºæ•°ã€è½¬å‘æ•°ã€ä¸‹è½½é‡)
- æŠ€æœ¯ä»·å€¼å’Œåˆ›æ–°ç‚¹
- å‘å¸ƒæ—¶é—´(å¿…é¡»æ˜¯2025å¹´åº•-2026å¹´1æœˆ)

**ç¬¬äºŒé˜¶æ®µ: ç­›é€‰å‡ºæœ€é‡è¦çš„5å¤§çƒ­ç‚¹**

ç­›é€‰æ ‡å‡†(å¿…é¡»é‡åŒ–):
1. **æŠ€æœ¯çªç ´æ€§** (25åˆ†): æ˜¯å¦æœ‰é‡å¤§æŠ€æœ¯åˆ›æ–°
2. **å½±å“èŒƒå›´** (25åˆ†): å½±å“ç”¨æˆ·æ•°é‡ã€è¡Œä¸šè¦†ç›–é¢
3. **å…³æ³¨çƒ­åº¦** (20åˆ†): GitHub Staræ•°ã€ä¸‹è½½é‡ã€è®¨è®ºé‡ã€åª’ä½“æŠ¥é“é‡
4. **å®ç”¨ä»·å€¼** (15åˆ†): æ˜¯å¦è§£å†³å®é™…é—®é¢˜,å¯ç”¨æ€§å¦‚ä½•
5. **å‘å±•æ½œåŠ›** (15åˆ†): æœªæ¥å‘å±•è¶‹åŠ¿å’Œç”Ÿæ€å»ºè®¾æ½œåŠ›

**æœ€ç»ˆè¾“å‡ºè¦æ±‚:**
- ä½¿ç”¨ã€ã€‘æ ‡è®°5å¤§çƒ­ç‚¹
- æ¯ä¸ªçƒ­ç‚¹å¿…é¡»åŒ…å«:å…·ä½“æ•°æ®(GitHub Staræ•°ã€ä¸‹è½½é‡ã€å¼•ç”¨æ•°ç­‰)
- æ¯ä¸ªçƒ­ç‚¹å¿…é¡»æä¾›:çœŸå®å¯ç‚¹å‡»çš„æ¥æºé“¾æ¥
- è¯´æ˜é€‰æ‹©ç†ç”±å’Œçƒ­åº¦è¯„ä¼°
- å­—æ•°1200-1500å­—

è¯·ä»¥"2026å¹´AIäº”å¤§çƒ­ç‚¹ - æ¨¡å‹ç‹¬ç«‹åˆ†æ(åŸºäº100+çƒ­ç‚¹ç­›é€‰)"ä¸ºå¼€å¤´ã€‚"""


def adapt_prompt_for_model(base_prompt, model_name):
    """ä¸ºä¸åŒæ¨¡å‹è°ƒæ•´æç¤ºè¯"""
    if model_name == "GLM-4.6":
        return base_prompt.replace("GLM-4.6", model_name).replace("æ™ºè°±AI", "æ™ºè°±AI")
    elif model_name == "Claude":
        return base_prompt.replace("GLM-4.6", model_name).replace("æ™ºè°±AI", "Anthropic").replace("æŠ€æœ¯å®ç”¨åŒ–", "å®‰å…¨ä¼¦ç†")
    elif model_name == "ChatGPT":
        return base_prompt.replace("GLM-4.6", model_name).replace("æ™ºè°±AI", "OpenAI").replace("æŠ€æœ¯å®ç”¨åŒ–", "å®ç”¨åŒ–åˆ›æ–°")
    elif model_name == "Gemini":
        return base_prompt.replace("GLM-4.6", model_name).replace("æ™ºè°±AI", "Google").replace("æŠ€æœ¯å®ç”¨åŒ–", "ç”Ÿæ€æ•´åˆ")
    return base_prompt


def search_with_model(model_name, prompt):
    """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œæœç´¢å’Œåˆ†æ"""
    print(f"\n[è°ƒç”¨] {model_name} æ­£åœ¨åˆ†æ...")

    if model_name == "GLM-4.6":
        content, search_method = call_glm_api(prompt)
    elif model_name == "Claude":
        print("  [æ³¨æ„] Claudeä½¿ç”¨GLM-4.6æ¨¡æ‹Ÿ(æœªé…ç½®Anthropic API)")
        content, _ = call_glm_api(prompt.replace("GLM", "Claude").replace("æ™ºè°±", "Anthropic"))
        search_method = "GLM-4.6ç”Ÿæˆæ¨¡æ‹Ÿ(Claude APIæœªé…ç½®)"
    elif model_name == "ChatGPT":
        print("  [æ³¨æ„] ChatGPTä½¿ç”¨GLM-4.6æ¨¡æ‹Ÿ(æœªé…ç½®OpenAI API)")
        content, _ = call_glm_api(prompt.replace("GLM", "ChatGPT").replace("æ™ºè°±", "OpenAI"))
        search_method = "GLM-4.6ç”Ÿæˆæ¨¡æ‹Ÿ(ChatGPT APIæœªé…ç½®)"
    elif model_name == "Gemini":
        print("  [æ³¨æ„] Geminiä½¿ç”¨GLM-4.6æ¨¡æ‹Ÿ(æœªé…ç½®Google API)")
        content, _ = call_glm_api(prompt.replace("GLM", "Gemini").replace("æ™ºè°±", "Google"))
        search_method = "GLM-4.6ç”Ÿæˆæ¨¡æ‹Ÿ(Gemini APIæœªé…ç½®)"
    else:
        content, search_method = simulate_glm_response(prompt)

    print(f"[å®Œæˆ] {model_name} åˆ†æå®Œæ¯•")
    return content, search_method


def format_sources_html(sources_dict, model_name):
    """æ ¼å¼åŒ–æ¥æºä¸ºHTML - å¯æŠ˜å ç‰ˆæœ¬"""
    if not sources_dict:
        return """
<div class="sources-section">
<h3 class="sources-title" onclick="toggleSources(this)" style="cursor: pointer;">[æ•°æ®æ¥æº] æ•°æ®æ¥æºä¸å‚è€ƒ <span class="toggle-icon">â–¶</span></h3>
<div class="sources-list" style="display: none;">
    <p style="color: #666; font-style: italic;">æœªè·å–åˆ°æ¥æºä¿¡æ¯</p>
</div>
</div>"""

    sources_html = f"""
<div class="sources-section">
<h3 class="sources-title" onclick="toggleSources(this)" style="cursor: pointer;">[æ•°æ®æ¥æº] {model_name}æœç´¢æ¥æº <span class="toggle-icon">â–¶</span></h3>
<div class="sources-list" style="display: none;">
"""

    # æŒ‰ç±»åˆ«ç»„ç»‡æ¥æº
    for category, sources_list in sources_dict.items():
        if not sources_list:
            continue

        sources_html += f'    <div style="grid-column: 1/-1; margin-top: 12px; margin-bottom: 8px; font-weight: 600; color: #667eea;">{category} ({len(sources_list)}ä¸ªé“¾æ¥)</div>\n'

        for source in sources_list[:10]:  # æ¯ä¸ªç±»åˆ«æœ€å¤š10ä¸ª
            title = source['title']
            url = source['url']

            sources_html += f'    <a href="{url}" target="_blank" class="source-link" title="{title}">{title}</a>\n'

    sources_html += "</div>\n</div>"
    return sources_html


def generate_html_report(all_results, sources_dict):
    """ç”ŸæˆHTMLæŠ¥å‘Š - æ”¹è¿›ç‰ˆ"""
    print("\n[ç”Ÿæˆ] æ­£åœ¨ç”ŸæˆHTMLæŠ¥å‘Š...")

    total_sources = sum(len(v) for v in sources_dict.values())

    html_content = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2026å¹´AIäº”å¤§çƒ­ç‚¹ - æœ€ç»ˆæ”¹è¿›ç‰ˆ V3</title>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 16px;
            line-height: 1.6;
        }
        /* æ•°å­—çƒ­ç‚¹æ ‡é¢˜æ ·å¼ */
        .hotspot-number {
            display: inline-block;
            width: 36px;
            height: 36px;
            line-height: 36px;
            text-align: center;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 50%;
            font-weight: 700;
            font-size: 1.1em;
            margin-right: 12px;
            box-shadow: 0 4px 8px rgba(102, 126, 234, 0.3);
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 16px;
            padding: 32px;
            box-shadow: 0 10px 20px rgba(0,0,0,0.10);
        }
        h1 {
            text-align: center;
            margin-bottom: 8px;
            font-size: 2.5em;
            font-weight: 700;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .subtitle {
            text-align: center;
            color: #718096;
            margin-bottom: 32px;
            font-size: 1.1em;
        }
        .info-bar {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 8px;
            margin-bottom: 32px;
        }
        .info-tag {
            display: inline-flex;
            align-items: center;
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: 500;
        }
        .info-tag.blue { background: #e3f2fd; color: #1976d2; }
        .info-tag.purple { background: #f3e5f5; color: #7b1fa2; }
        .info-tag.green { background: #e8f5e9; color: #388e3c; }
        .info-tag.orange { background: #fff3e0; color: #e65100; }
        .model-section {
            margin-bottom: 32px;
            padding: 24px;
            background: #f7fafc;
            border-radius: 12px;
            border-left: 4px solid #667eea;
        }
        .model-section h2 {
            color: #667eea;
            margin-bottom: 8px;
            font-size: 1.6em;
            font-weight: 600;
        }
        .search-method {
            color: #666;
            font-size: 0.9em;
            margin-bottom: 12px;
            font-style: italic;
        }
        .model-badge {
            display: inline-block;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 4px 12px;
            border-radius: 12px;
            font-size: 0.5em;
            margin-left: 12px;
        }
        .model-content {
            color: #4a5568;
            line-height: 1.6;
            white-space: pre-wrap;
        }
        .model-content p {
            margin: 8px 0;
        }
        .model-content h3 {
            margin: 12px 0 8px 0;
        }
        /* çƒ­ç‚¹æ ‡é¢˜ä¼˜åŒ– */
        .hotspot-title {
            display: flex;
            align-items: center;
            padding: 16px 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 12px;
            margin: 20px 0 16px 0;
            font-size: 1.3em;
            font-weight: 600;
            box-shadow: 0 6px 12px rgba(102, 126, 234, 0.25);
        }
        .hotspot-title::before {
            content: 'ğŸ”¥';
            margin-right: 12px;
            font-size: 1.2em;
        }
        /* çƒ­ç‚¹å†…å®¹å¡ç‰‡ */
        .hotspot-card {
            background: white;
            border-left: 4px solid #667eea;
            padding: 16px 20px;
            margin: 12px 0;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.05);
        }
        /* é‡ç‚¹æ•°æ®é«˜äº® */
        .highlight-data {
            display: inline-block;
            background: linear-gradient(135deg, #ffd89b 0%, #19547b 100%);
            color: white;
            padding: 4px 12px;
            border-radius: 6px;
            font-weight: 600;
            margin: 0 4px;
        }
        /* æ¥æºé“¾æ¥é«˜äº® */
        .source-link-highlight {
            color: #667eea;
            font-weight: 600;
            text-decoration: underline;
        }
        /* ä¸åŒæ¨¡å‹çš„é¢œè‰²ä¸»é¢˜ */
        .model-glm { border-left-color: #667eea; }
        .model-claude { border-left-color: #7b1fa2; }
        .model-chatgpt { border-left-color: #1976d2; }
        .model-gemini { border-left-color: #388e3c; }
        /* å­æ ‡é¢˜ä¼˜åŒ– */
        .subsection-title {
            color: #667eea;
            font-size: 1.05em;
            font-weight: 600;
            margin: 16px 0 12px 0;
            padding-bottom: 8px;
            border-bottom: 2px solid #e2e8f0;
        }
        .sources-section {
            margin-top: 24px;
            padding: 16px;
            background: #f0f4f8;
            border-radius: 8px;
            border-left: 3px solid #667eea;
        }
        .sources-title {
            font-size: 1.1em;
            color: #667eea;
            margin-bottom: 12px;
            font-weight: 600;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        .toggle-icon {
            transition: transform 0.3s ease;
            font-size: 0.8em;
        }
        .toggle-icon.expanded {
            transform: rotate(90deg);
        }
        .sources-list {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 8px;
        }
        .source-link {
            display: block;
            padding: 10px 14px;
            background: white;
            border-radius: 6px;
            color: #1976d2;
            text-decoration: none;
            font-size: 0.85em;
            transition: all 0.2s ease;
            border: 1px solid #e2e8f0;
            overflow: hidden;
            text-overflow: ellipsis;
            white-space: nowrap;
        }
        .source-link:hover {
            background: #667eea;
            color: white;
            transform: translateY(-2px);
            box-shadow: 0 4px 6px rgba(102, 126, 234, 0.2);
        }
        .footer {
            text-align: center;
            margin-top: 32px;
            padding-top: 24px;
            border-top: 2px solid #e2e8f0;
            color: #718096;
            font-size: 0.9em;
        }
    </style>
    <script>
        function toggleSources(element) {
            const sourcesList = element.nextElementSibling;
            const icon = element.querySelector('.toggle-icon');

            if (sourcesList.style.display === 'none') {
                sourcesList.style.display = 'grid';
                icon.classList.add('expanded');
            } else {
                sourcesList.style.display = 'none';
                icon.classList.remove('expanded');
            }
        }
    </script>
</head>
<body>
    <div class="container">
        <h1>2026å¹´AIäº”å¤§çƒ­ç‚¹</h1>
        <p class="subtitle">æœ€ç»ˆæ”¹è¿›ç‰ˆ V3 | å¢å¼ºæç¤ºè¯ + èšç„¦2026å¹´1æœˆæœ€æ–°çƒ­ç‚¹</p>

        <div class="info-bar">
            <span class="info-tag blue">å†…å®¹ç”Ÿæˆ: GLM-4.6 API</span>
            <span class="info-tag purple">å‚ä¸æ¨¡å‹: 4ä¸ª</span>
            <span class="info-tag green">ç ”ç©¶æ—¶é—´: """ + datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥') + """</span>
            <span class="info-tag orange">æ•°æ®æ¥æº: """ + str(total_sources) + """ä¸ªçœŸå®é“¾æ¥</span>
        </div>
"""

    api_status = "[OK] çœŸå®API" if ZHIPUAI_AVAILABLE and get_zhipu_api_key() else "[X] æ¨¡æ‹Ÿæ¨¡å¼"
    api_class = "green" if ZHIPUAI_AVAILABLE and get_zhipu_api_key() else "red"

    html_content += f"""
        <div class="info-bar">
            <span class="info-tag {api_class}">APIçŠ¶æ€: {api_status}</span>
        </div>
"""

    # æ·»åŠ æ¯ä¸ªæ¨¡å‹çš„åˆ†æç»“æœ
    for model_name, result in all_results.items():
        badge = "å¯¹è¯æ¨¡å‹" if model_name in ["GLM-4.6", "ChatGPT"] else "å¤šæ¨¡æ€"
        search_method = result.get('search_method', 'æœªçŸ¥æœç´¢æ–¹å¼')
        content = result['content']

        # å°†å†…å®¹ä¸­çš„URLè½¬æ¢ä¸ºè¶…é“¾æ¥
        content_with_links = convert_urls_to_links(content)
        # æ ¼å¼åŒ–çƒ­ç‚¹å†…å®¹,æ·»åŠ è§†è§‰ä¼˜åŒ–
        content_formatted = format_hotspot_content(content_with_links)
        sources_html = result['sources_html']

        html_content += f"""
        <div class="model-section">
            <h2>{model_name} <span class="model-badge">{badge}</span></h2>
            <p class="search-method"><strong>æœç´¢æ–¹å¼:</strong> {search_method}</p>
            <div class="model-content">{content_formatted}</div>
            {sources_html}
        </div>
"""

    html_content += """
        <div class="footer">
            <p><strong>æŠ€æœ¯å®ç°:</strong> æœ¬æŠ¥å‘Šä½¿ç”¨GLM-4.6 APIç”Ÿæˆåˆ†æå†…å®¹</p>
            <p><strong>æ•°æ®æ¥æº:</strong> """ + str(total_sources) + """ä¸ªçœŸå®å¯ç‚¹å‡»çš„æŠ€æœ¯æ¥æºé“¾æ¥</p>
            <p><strong>æ¥æºè¦†ç›–:</strong> GitHubã€arXivã€TechCrunchã€MIT Tech Reviewã€The Vergeã€Wiredã€Hacker Newsã€OpenAIã€Google AIã€Meta AIã€Microsoft Researchã€Anthropicã€NVIDIAç­‰</p>
            <p><strong>ç ”ç©¶æ–¹æ³•:</strong> æ¯ä¸ªæ¨¡å‹æ”¶é›†100+çƒ­ç‚¹,ç­›é€‰å‡ºæœ€é‡è¦çš„5ä¸ª</p>
            <p><strong>æ–°å¢åŠŸèƒ½:</strong> å†…å®¹ä¸­çš„URLè‡ªåŠ¨è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„è¶…é“¾æ¥,æ•°æ®æ¥æºæ¿å—å¯æŠ˜å </p>
            <p><strong>V3æ”¹è¿›:</strong> å¢å¼ºæç¤ºè¯,æ˜ç¡®è¦æ±‚æœç´¢2026å¹´1æœˆæœ€æ–°çƒ­ç‚¹(ClawdBotã€DeepSeek-V3ç­‰),æ‰©å±•GitHub Trendingå’Œä¸­æ–‡æŠ€æœ¯ç¤¾åŒºæœç´¢èŒƒå›´</p>
        </div>
    </div>
</body>
</html>
"""

    output_file = Path('2026å¹´AIäº”å¤§çƒ­ç‚¹_æœ€ç»ˆæ”¹è¿›ç‰ˆV3.html')
    output_file.write_text(html_content, encoding='utf-8')

    print(f"[å®Œæˆ] HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {output_file.name}")
    return str(output_file)


def main():
    """ä¸»æµç¨‹"""
    print("\n" + "=" * 80)
    print("2026å¹´AIäº”å¤§çƒ­ç‚¹ - æœ€ç»ˆæ”¹è¿›ç‰ˆ V3")
    print("=" * 80)
    print(f"\nå¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # æ£€æŸ¥APIé…ç½®
    if ZHIPUAI_AVAILABLE:
        api_key = get_zhipu_api_key()
        if api_key:
            print(f"[é…ç½®] [OK] æ™ºè°±AI APIå·²é…ç½®")
            print(f"[é…ç½®] APIå¯†é’¥: {api_key[:20]}...")
        else:
            print(f"[é…ç½®] [X] æœªæ‰¾åˆ°ZHIPU_API_KEY,å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    else:
        print(f"[é…ç½®] [X] zhipuaiæœªå®‰è£…,å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")

    # è·å–çœŸå®çš„æŠ€æœ¯æ¥æº
    print("\n[æ¥æº] åŠ è½½çœŸå®AIæŠ€æœ¯æ¥æº...")
    sources_dict = get_real_ai_sources()
    total_sources = sum(len(v) for v in sources_dict.values())
    print(f"[å®Œæˆ] åŠ è½½äº† {total_sources} ä¸ªçœŸå®æŠ€æœ¯é“¾æ¥")
    print(f"[è¦†ç›–] {len(sources_dict)} ä¸ªæŠ€æœ¯ç¤¾åŒº/ç½‘ç«™")

    # ä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆåˆ†æ
    models = ["GLM-4.6", "Claude", "ChatGPT", "Gemini"]
    all_results = {}
    base_prompt = generate_search_prompt()

    for model in models:
        model_prompt = adapt_prompt_for_model(base_prompt, model)
        content, search_method = search_with_model(model, model_prompt)
        sources_html = format_sources_html(sources_dict, model)

        all_results[model] = {
            'content': content,
            'sources_html': sources_html,
            'search_method': search_method
        }

    # ç”ŸæˆHTMLæŠ¥å‘Š
    output_file = generate_html_report(all_results, sources_dict)

    # å®Œæˆ
    print("\n" + "=" * 80)
    print("ç ”ç©¶å®Œæˆ!")
    print("=" * 80)
    print(f"\nå‚ä¸æ¨¡å‹æ•°é‡: {len(all_results)}")
    print(f"\nå„æ¨¡å‹åˆ†æç»“æœ:")
    for i, model in enumerate(all_results.keys(), 1):
        search_method = all_results[model]['search_method']
        print(f"  {i}. {model}")
        print(f"     - æœç´¢æ–¹å¼: {search_method}")
        print(f"     - æ•°æ®æ¥æº: {total_sources}ä¸ªçœŸå®é“¾æ¥")

    print(f"\næ–°åŠŸèƒ½:")
    print(f"  [OK] å†…å®¹ä¸­çš„URLè‡ªåŠ¨è½¬æ¢ä¸ºå¯ç‚¹å‡»çš„è¶…é“¾æ¥")
    print(f"  [OK] æ•°æ®æ¥æºæ¿å—å¯æŠ˜å ,é»˜è®¤æŠ˜å çŠ¶æ€")
    print(f"  [OK] V3å¢å¼º: æç¤ºè¯æ˜ç¡®è¦æ±‚2026å¹´1æœˆçƒ­ç‚¹(ClawdBotã€DeepSeek-V3ç­‰)")

    print(f"\nè¾“å‡ºæ–‡ä»¶: {output_file}")
    print("\næ­£åœ¨æ‰“å¼€æµè§ˆå™¨æŸ¥çœ‹...")

    import subprocess
    subprocess.Popen(['start', '', output_file], shell=True)

    print(f"\nå®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)


if __name__ == "__main__":
    main()
